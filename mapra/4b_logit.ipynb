{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "from mapra import prep\n",
    "\n",
    "from multiprocessing import Process\n",
    "from time import sleep\n",
    "\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.metrics import auc, plot_roc_curve\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "sns.set_theme(style='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/quirin/PYTHON/mapra\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(prep)\n",
    "data = prep.dataset()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def do_work(extend, modify, metric, func, thresholds):\n",
    "\n",
    "    df = data.dataframe_repeats_avg(reduced=True)\n",
    "\n",
    "    mbeds = data.fetch_df_with_pairwise_distances(extend=extend, df=df, modify=modify, func=func)\n",
    "    \"\"\"\n",
    "    :param extend: The number of additional neighbours to include on each side\n",
    "    :param df: optional dataframe, otherwise will be dataframe_abbrev(reduced=reduced)\n",
    "    :param reduced: default is True, if only the redundancy-reduced dataset shall be loaded from the df\n",
    "    :param modify: 'flip' distances for negative changes, use the 'abs' value, only 'pos' or 'neg'\n",
    "    :param scaler: 'std' or 'minmax'\n",
    "    :param func: the function to handle compound mutations: np.mean, sum, max, min\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # mbeds.data\n",
    "\n",
    "\n",
    "    # and convert changes to discrete classes\n",
    "    # y_train = y_train.apply(lambda f: '--' if f < -10 else '-' if f < -1 else '=' if f < 1 else '+' if f < 10 else '++')\n",
    "    # y_train = y_train.apply(lambda f: -1 if f <= -1 else 0 if f <= 1 else 1)\n",
    "    # y_train = y_train.apply(lambda f: -1 if f <= 0 else 1)\n",
    "    # y_train = y_train.apply(lambda f: 0 if abs(f) <= 2 else 1)\n",
    "\n",
    "    # metric = 'euclidean'\n",
    "    df = mbeds.data.loc[(mbeds.data.metric == mbeds.metric_labels.index(metric)),\n",
    "                        [c for c in mbeds.data.columns if c != 'metric']]\n",
    "    # # create class labels\n",
    "    # thresholds = [3, 1, 1.5]\n",
    "    df['label'] = df.apply(lambda gdf: 0 if abs(gdf.change) <= thresholds[int(gdf.delta)] else 1, axis=1)\n",
    "\n",
    "    # plotting prep\n",
    "    fig, axs = plt.subplots(3, 4, figsize=(14, 12), gridspec_kw={'width_ratios': [1, 1, 1, .4]})\n",
    "    cmap = sns.color_palette('viridis', 3)\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs, aucs = list(), list()\n",
    "    test_size = .2\n",
    "\n",
    "    for i, delta in enumerate(mbeds.delta_labels):\n",
    "        # select the records for this delta\n",
    "        dfn = df.loc[df.delta == i]\n",
    "\n",
    "        sns.regplot(data=dfn,\n",
    "                ax=axs[i, 0],\n",
    "                x='dist', y='change',\n",
    "                color=cmap[i],\n",
    "                marker='+',\n",
    "                scatter_kws={'s': 3, 'alpha': .2},\n",
    "                fit_reg=False, logistic=True)\n",
    "        axs[i, 0].set(ylabel=data.tex_lookup[delta], xlabel='')\n",
    "        axs[i, 0].axhline(y=thresholds[i], lw=2, color='.5', alpha=.8)\n",
    "\n",
    "        # make the scatterplot\n",
    "        sns.regplot(data=dfn,\n",
    "                    ax=axs[i, 1],\n",
    "                    x='dist', y='label',\n",
    "                    marker='+',\n",
    "                    y_jitter=.06, color=cmap[i],\n",
    "                    scatter_kws={'s': 3, 'alpha': .2},\n",
    "                    fit_reg=False, logistic=True)\n",
    "        axs[i, 1].set(xlabel='', yticks=[0, 1], ylabel='',\n",
    "                      yticklabels=[f'≤ {thresholds[i]}', f'> {thresholds[i]}'])\n",
    "        axs[i, 1].tick_params(axis='y', labelrotation=90)\n",
    "        axs[i, 1].yaxis.labelpad = -10\n",
    "\n",
    "        # fetch the training data\n",
    "        X, y = np.array(dfn['dist']).reshape(-1, 1), np.array(dfn['label'])\n",
    "\n",
    "        # split into test and training data\n",
    "        X, x_test, y, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "        n_splits=8\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        clf = linear_model.LogisticRegressionCV(random_state=42,\n",
    "                                                cv=cv,  # use existing splitter\n",
    "                                                refit=True)  # build best model in the end\n",
    "\n",
    "        for j, (train, test) in enumerate(cv.split(X, y)):\n",
    "            clf.fit(X[train], y[train])\n",
    "\n",
    "            # plot a ROC curve\n",
    "            viz = plot_roc_curve(clf, X[test], y[test], lw=1, color='.5', alpha=.3, ax=axs[i, 2])\n",
    "            interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "            aucs.append(viz.roc_auc)\n",
    "\n",
    "            # plot the loss curves\n",
    "            x_line = np.linspace(0, max(X), 100)\n",
    "            loss = expit(x_line * clf.coef_ + clf.intercept_).ravel()\n",
    "            axs[i, 1].plot(x_line, loss, lw=1, color='.5', alpha=.3)\n",
    "\n",
    "        # correlations\n",
    "        pearson_corr = np.corrcoef(dfn[['dist', 'change']], rowvar=False)[0, 1]\n",
    "        axs[i, 0].text(.07, .9, f'corr: {pearson_corr:.2f}', transform=axs[i, 0].transAxes)\n",
    "\n",
    "        # label class sizes\n",
    "        axs[i, 1].text(.07, .75, f'{len(dfn.loc[dfn.label == 1]):.0f}', transform=axs[i, 1].transAxes)\n",
    "        axs[i, 1].text(.07, .20, f'{len(dfn.loc[dfn.label == 0]):.0f}', transform=axs[i, 1].transAxes)\n",
    "\n",
    "        # plot the overall loss curve\n",
    "        x_line = np.linspace(0, max(X), 100)\n",
    "        loss = expit(x_line * clf.coef_ + clf.intercept_).ravel()\n",
    "        axs[i, 1].plot(x_line, loss, lw=2.5, color=cmap[i], alpha=1)\n",
    "\n",
    "        # plot the diagonal\n",
    "        axs[i, 2].plot([0, 1], [0, 1], lw=1, color='.5', alpha=.6)\n",
    "\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "        axs[i, 2].plot(mean_fpr, mean_tpr, color=cmap[i], lw=2.5, alpha=1)\n",
    "\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        axs[i, 2].fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2)\n",
    "\n",
    "        axs[i, 2].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05])  #, title=\"Receiver operating characteristic example\")\n",
    "        axs[i, 2].text(.04, .85, f'AUC= {mean_auc:0.2f}$\\pm${std_auc:.2f}\\n{n_splits}×CV', transform=axs[i, 2].transAxes)\n",
    "        axs[i, 2].get_legend().remove()\n",
    "        axs[i, 2].set(xlabel='FPR', ylabel='TPR', xticks=[0, 1], yticks=[0, 1])\n",
    "        axs[i, 2].xaxis.labelpad = -10\n",
    "        axs[i, 2].yaxis.labelpad = -10\n",
    "\n",
    "        # make final test\n",
    "        f = metrics.plot_confusion_matrix(clf, x_test, y_test, ax=axs[i, 3],\n",
    "                                          cmap='binary', colorbar=False)\n",
    "        axs[i, 3].yaxis.tick_right()\n",
    "        axs[i, 3].xaxis.set_label_position('top')\n",
    "\n",
    "        axs[i, 3].set(ylabel='Truth', xlabel='Prediction',\n",
    "                      xticklabels=[f'≤ {thresholds[i]}', f'> {thresholds[i]}'],\n",
    "                      yticklabels=[f'≤ {thresholds[i]}', f'> {thresholds[i]}'][::-1])\n",
    "\n",
    "        axs[i, 3].text(0, 1.1, f'Test size: {len(x_test)}\\n             ={test_size * 100:.0f}%\\n',\n",
    "                       transform=axs[i, 3].transAxes)\n",
    "        axs[i, 3].text(0, -.6, f'Accuracy: {clf.score(x_test, y_test):.2f}',\n",
    "                       transform=axs[i, 3].transAxes)\n",
    "\n",
    "    wd = Path('.').resolve().parent / 'plots' / 'comp'\n",
    "    Path.mkdir(wd, parents=True, exist_ok=True)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(wd / f'df__euclidean_{1+ 2*extend}_{modify}_{func.__name__}_{\"-\".join([str(t) for t in thresholds])}.png',\n",
    "              dpi=300, bbox_inches=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /home/quirin/PYTHON/mapra/all_sequences_prothermdb_HALF.h5 ...\n",
      "starting 0\n",
      "reading /home/quirin/PYTHON/mapra/all_sequences_prothermdb_HALF.h5 ...\n",
      "starting 1\n",
      "reading /home/quirin/PYTHON/mapra/all_sequences_prothermdb_HALF.h5 ...\n",
      "starting 2\n",
      "reading /home/quirin/PYTHON/mapra/all_sequences_prothermdb_HALF.h5 ...\n",
      "starting 3\n",
      "reading /home/quirin/PYTHON/mapra/all_sequences_prothermdb_HALF.h5 ...\n",
      "starting 4\n",
      "reading /home/quirin/PYTHON/mapra/all_sequences_prothermdb_HALF.h5 ...\n",
      "starting 5\n",
      "reading /home/quirin/PYTHON/mapra/all_sequences_prothermdb_HALF.h5 ...\n",
      "starting 6\n",
      "reading /home/quirin/PYTHON/mapra/all_sequences_prothermdb_HALF.h5 ...\n",
      "starting 7\n",
      "reading /home/quirin/PYTHON/mapra/all_sequences_prothermdb_HALF.h5 ...\n",
      "starting 8\n",
      "starting 9\n",
      "reading /home/quirin/PYTHON/mapra/all_sequences_prothermdb_HALF.h5 ...\n",
      "starting 10\n",
      "reading /home/quirin/PYTHON/mapra/all_sequences_prothermdb_HALF.h5 ...\n",
      "starting 11\n",
      "reading /home/quirin/PYTHON/mapra/all_sequences_prothermdb_HALF.h5 ...\n",
      "read 8113 embeddings for 323 proteins, each SAV with 5 neighbors on each side, wrote to /home/quirin/PYTHON/mapra/extracted_5.pkl\n",
      "read 8113 embeddings for 323 proteins, each SAV with 5 neighbors on each side, wrote to /home/quirin/PYTHON/mapra/extracted_5.pkl\n",
      "read 8113 embeddings for 323 proteins, each SAV with 5 neighbors on each side, wrote to /home/quirin/PYTHON/mapra/extracted_5.pkl\n",
      "read 8113 embeddings for 323 proteins, each SAV with 5 neighbors on each side, wrote to /home/quirin/PYTHON/mapra/extracted_5.pkl\n",
      "read 8113 embeddings for 323 proteins, each SAV with 5 neighbors on each side, wrote to /home/quirin/PYTHON/mapra/extracted_5.pklread 8113 embeddings for 323 proteins, each SAV with 5 neighbors on each side, wrote to /home/quirin/PYTHON/mapra/extracted_5.pkl\n",
      "read 8113 embeddings for 323 proteins, each SAV with 5 neighbors on each side, wrote to /home/quirin/PYTHON/mapra/extracted_5.pkl\n",
      "read 8113 embeddings for 323 proteins, each SAV with 5 neighbors on each side, wrote to /home/quirin/PYTHON/mapra/extracted_5.pkl\n",
      "\n",
      "read 8113 embeddings for 323 proteins, each SAV with 5 neighbors on each side, wrote to /home/quirin/PYTHON/mapra/extracted_5.pklread 8113 embeddings for 323 proteins, each SAV with 5 neighbors on each side, wrote to /home/quirin/PYTHON/mapra/extracted_5.pklread 8113 embeddings for 323 proteins, each SAV with 5 neighbors on each side, wrote to /home/quirin/PYTHON/mapra/extracted_5.pkl\n",
      "\n",
      "read 8113 embeddings for 323 proteins, each SAV with 5 neighbors on each side, wrote to /home/quirin/PYTHON/mapra/extracted_5.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "extend = 5\n",
    "modify = 'abs'\n",
    "metric = 'euclidean'\n",
    "thresholds = [3, 1, 1.5]\n",
    "\n",
    "procs = []\n",
    "i = 0\n",
    "for modify in ['pos', 'flip', 'abs']:\n",
    "    for func in [sum, max]:\n",
    "        for thresholds in [[3,1,1.5], [10, 3, 3]]:\n",
    "            proc = Process(target=do_work,\n",
    "                           args=(extend, modify, metric, func, thresholds))\n",
    "            proc.start()\n",
    "            print(f'starting {i}')\n",
    "            procs.append(proc)\n",
    "            i += 1\n",
    "            sleep(.5)\n",
    "for proc in procs:\n",
    "    proc.join()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}